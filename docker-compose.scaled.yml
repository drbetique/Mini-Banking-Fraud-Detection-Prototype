# Docker Compose Configuration for Horizontal Scaling
# This file demonstrates how to run multiple instances of services for high availability

version: '3.8'

services:
  # ==================== NGINX LOAD BALANCER ====================
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Status page
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro  # SSL certificates (production)
      - nginx_logs:/var/log/nginx
    depends_on:
      - api-1
      - api-2
      - api-3
    restart: unless-stopped
    networks:
      - fraud-network

  # ==================== DATABASE (PRIMARY) ====================
  db:
    image: postgres:13-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=bankdb
      - POSTGRES_MAX_CONNECTIONS=200  # Increased for multiple API instances
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - fraud-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # ==================== KAFKA & ZOOKEEPER ====================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped
    networks:
      - fraud-network

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 6  # Increased partitions for parallel processing
    restart: unless-stopped
    networks:
      - fraud-network

  # ==================== MLFLOW ====================
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "5001:5000"
    volumes:
      - mlflow_data:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_BACKEND_STORE_URI=file:///mlflow/mlruns
      - MLFLOW_ARTIFACT_STORE_URI=file:///mlflow/artifacts
      - GUNICORN_CMD_ARGS=--timeout 60
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri file:///mlflow/mlruns --default-artifact-root file:///mlflow/artifacts --allowed-hosts '*'
    restart: unless-stopped
    networks:
      - fraud-network

  # ==================== API INSTANCES (3 replicas) ====================
  api-1:
    build:
      context: .
      dockerfile: Dockerfile.api
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db/bankdb
      - AZURE_API_KEY=${AZURE_API_KEY}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - INSTANCE_ID=api-1
    depends_on:
      - db
      - kafka
      - redis
    restart: unless-stopped
    networks:
      - fraud-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  api-2:
    build:
      context: .
      dockerfile: Dockerfile.api
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db/bankdb
      - AZURE_API_KEY=${AZURE_API_KEY}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - INSTANCE_ID=api-2
    depends_on:
      - db
      - kafka
      - redis
    restart: unless-stopped
    networks:
      - fraud-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  api-3:
    build:
      context: .
      dockerfile: Dockerfile.api
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db/bankdb
      - AZURE_API_KEY=${AZURE_API_KEY}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - INSTANCE_ID=api-3
    depends_on:
      - db
      - kafka
      - redis
    restart: unless-stopped
    networks:
      - fraud-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ==================== DETECTION SERVICE (2 replicas) ====================
  # Uses Kafka consumer groups for automatic load balancing
  detection-service-1:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8001:8001"
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db/bankdb
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=transactions_topic
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - PROMETHEUS_PORT=8001
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - INSTANCE_ID=detection-1
    depends_on:
      - db
      - kafka
      - mlflow
      - redis
    command: python detection_service.py
    restart: unless-stopped
    networks:
      - fraud-network

  detection-service-2:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "8002:8001"
    volumes:
      - .:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db/bankdb
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=transactions_topic
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - PROMETHEUS_PORT=8001
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - INSTANCE_ID=detection-2
    depends_on:
      - db
      - kafka
      - mlflow
      - redis
    command: python detection_service.py
    restart: unless-stopped
    networks:
      - fraud-network

  # ==================== REDIS (WITH REPLICATION) ====================
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    networks:
      - fraud-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 768M

  # ==================== PROMETHEUS ====================
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus_alerts.yml:/etc/prometheus/prometheus_alerts.yml
      - prometheus_data:/prometheus
    command: --config.file=/etc/prometheus/prometheus.yml --web.enable-remote-write-receiver --web.enable-admin-api
    depends_on:
      - api-1
      - api-2
      - api-3
      - detection-service-1
      - detection-service-2
    restart: unless-stopped
    networks:
      - fraud-network

  # ==================== GRAFANA ====================
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - fraud-network

volumes:
  postgres_data:
  mlflow_data:
  prometheus_data:
  grafana_data:
  redis_data:
  nginx_logs:

networks:
  fraud-network:
    driver: bridge
